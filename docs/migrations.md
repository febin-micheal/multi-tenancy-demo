# Of Modular Alembic Migrations
This piece was born more out of surprise than anything else. Given how 
much we take modularity for granted, I assumed it would be a first class 
concept in something as widely popular as <u>[Alembic](https://alembic.sqlalchemy.org/en/latest/index.html)</u>(which for the record is 
quite stellar and I have enjoyed working with it).

The goal here is to share an approach to this problem that’s worked well for 
my team and hopefully save you a few nights along the way.

## Goal
Track a project’s applications’ migrations separately, both conceptually and 
in alembic.

## Approach
If you’ve worked with a recent version of Django, you’ll agree handling 
migrations there are pretty seamless. In particular, the approach with 
applications is intuitive. The goal was to replicate something of the sort 
here. The assumption is that each app has at least one separate schema. 
I have not yet tried using a schema cross app, but there’s no reason it should 
fail. Our team uses a `dev` script at the top of a project directory with 
wrappers to common commands. At the end of this we’d like to have at least 
three commands;

* `./dev makemigrations`: generate migrations for recent model 
  changes(we’ll default to auto generated migrations)
* `./dev migrate <app_name>`: apply generated migrations to the database
* `./dev downgrade <app_name>`: revert the last applied migration
* Bonus- `./dev create <app_name>`: sets up a new application

## Show me the code
If you have not yet given the docs a run through, now would be a good time. 
Otherwise, going forward, I assume you have run the `init` command and have 
an environment similar to <u>[this](https://alembic.sqlalchemy.org/en/latest/tutorial.html#the-migration-environment)</u>.

### Set Up Common Migration Functionality
* Add an `[alembic]` section, which will hold the config to be used when 
  now a `--name` is not specified when running `alembic` commands. We’ll 
  use this for things like checking collective head statuses. For now, just 
  add this to that section;

```
[alembic] 
# universal config
script_location = alembic # dir where your common `env.py` file lives
```

* Modify the env.py file generated by alembic to;

```python
from logging.config import fileConfig
from typing import List

from sqlalchemy import engine_from_config, MetaData
from sqlalchemy import pool
from alembic import context

import settings

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers
fileConfig(config.config_file_name)

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def _include_object(target_schema):
    def include_object(obj, name, object_type, reflected, compare_to):
        if object_type == "table":
            return obj.schema in target_schema
        else:
            return True

    return include_object


def _run_migrations_offline(target_metadata, schema):
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = settings.CONNECTION_STRING
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        include_schemas=True,  #1
        include_object=_include_object(schema),  #1
        compare_type=True,
    )

    with context.begin_transaction():
        context.run_migrations()


def _run_migrations_online(target_metadata, schema):
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
        url=settings.CONNECTION_STRING,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            include_schemas=True,  #2
            include_object=_include_object(schema),  #2
            compare_type=True,
        )

        with context.begin_transaction():
            context.run_migrations()

#3
def run_migrations(metadata: MetaData, schema: List[str]):
    if context.is_offline_mode():
        _run_migrations_offline(metadata, schema)
    else:
        _run_migrations_online(metadata, schema)
```

### _Key changes_

### 1, 2.

The default generated file does not have the `include_schemas` flag turned 
on. I faced difficulty with getting alembic to find model changes across 
schemas with this flag off. However, turning that on also led to migrations 
in other schemas being wrongly attributed to whatever schema I was trying 
to migrate at the time. Addressing this is where the `include_object` 
argument comes in. It takes a method which when called should return 
`True` or `False` based on whether or not it should be included in the 
generated migration file.

### 3.

Running the migrations is no longer done when the file is loaded/ 
executed, rather when this method is called. The schema allows us to do the 
filtering mentioned earlier**.

### Creating An App

Hopefully, by the end of this, we’ll have a command(`./dev create <app_name>`) 
to automatically do this boiler plate work, but until then, add these steps to 
your README because you’ll need to do them every time you add a new application.

* Add a migrations directory to your application(convention here is 
  `<app_name>/migrations`, but feel free to follow your project’s convention, 
  e.g `migrations/<app_name>`).
* Copy the `script.py.mako` file to this directory.***
* Create an `env.py` file in this directory and add;

```python
from alembic.env import run_migrations  # or wherever your common `env.py` file is
from <app_name>.models import Base

metadata = Base.metadata
schema = ["some_schema", "some_other_schema"]

run_migrations(metadata, schema)
```

The format of this file will be more or less the same for all applications, with
the relevant schema and `Base` model class swapped in.

* **Add your app’s section** with the appropriate attributes to `alembic.ini`. 
  This will suffice for now;

```
[your_app_name]
# <app_name> specific settings
script_location = <app_name>/migrations
```

* **Add your app’s migration directory to** 
  `alembic.ini/version_locations`. This will allow alembic keep track of all 
  the places your migrations live even when you are running alembic 
  using a different section of the alembic.ini file with different version 
  locations and have different version bases.

* **Create your first migration;**

```
alembic \
    --name=<app_name> \
    revision -m "<message e.g Initial: Setup Models>" \
    --head=base \
    --branch-label=<app_name> \
    --version-path=<path to your app's migration files e.g <app_name>/migrations/versions> \
    [ --autogenerate]
```

Let’s break this down.

* `--name` allows us to choose the section in the config file to use****.
* `--head=base` says to start this migrations tree at the root, meaning it’ll 
  have no previous dependencies. This makes sense for our application approach.
* `--branch-label` will be the name of this migration branch. Read about 
  <u>branches</u> in the docs to dig into this.
* `--version-path` is pretty self explanatory. You probably want to auto 
  discover model changes, so include the `--autogenerate` flag.
* **Migrate.**

  Run this app’s first migration.`alembic --name=<app_name> upgrade <app_name>@head`.

**Add The Convenience Commands To Your `dev` Script**

After running the previous steps and after setting these up, you’ll subsequently 
just be running `./dev makemigrations` when your models have new changes 
and `./dev migrate` to apply them.

* Add a `./dev makemigrations -m="Some message" <app_name>` command 
  that you’ll run for migrations going forward*. That command runs;

```
alembic \
    --name=<app_name> \
    revision \
    --message="Some message(your migrate command should probably take this in as an option)" \
    --head=<app_name>@head
    --autogenerate
```

_*For the first migration in an app, you’ll run the command in **Create your 
first migration** above and for subsequent ones, you’ll run this one._

* Add a `./dev migrate <app_name>` command that runs `alembic --name=<app_name> upgrade <app_name>@head` like above.
* Add a `.dev downgrade <app_name>` command that runs `alembic --name<app_name> downgrade <app_name>@head-1`.

### Footnotes

* **: If you have a single schema per app, you could even exclude this and 
  pick the schema from the `metadata`.
* ***: If you figure out a way of having `alembic` use the earlier generated 
  `env` file, while at the same time pointing to a script location that’s not 
  that directory, let me know :)
* ****: We can do interesting things with this one. For example, I tried 
  auto discovering the schema and modules based on this but it didn’t 
  quite end well. That’s something that might still be possible and might 
  eliminate the need for the app specific `env` files.